{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Data Collection\n",
        "You can use a publicly available dataset like the IMDb Reviews dataset or Amazon Product Reviews. For this example, I'll use the IMDb Reviews dataset, which is widely used for sentiment analysis.\n",
        "\n",
        "Dataset Link: IMDb Reviews Dataset\n",
        "\n",
        "The dataset contains 50,000 movie reviews labeled as positive or negative."
      ],
      "metadata": {
        "id": "z41Y_1am8xvr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import csv\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, f1_score, roc_auc_score, precision_recall_curve, auc"
      ],
      "metadata": {
        "id": "W_6uHMMyA4rE"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download NLTK data (only need to run once)\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y616m833EFJD",
        "outputId": "08c4c0fc-f05c-42c0-875e-60cda8ac615e"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Load the dataset\n",
        "file_path = '/content/IMDB_Dataset.csv'\n",
        "df = pd.read_csv(file_path, quoting=csv.QUOTE_NONE, on_bad_lines='skip')\n",
        "\n",
        "# 2. Preprocess the text data\n",
        "df['review'] = df['review'].fillna('')\n",
        "\n",
        "# Preprocess the text data\n",
        "def clean_text(text):\n",
        "    if isinstance(text, str):  # Ensure the text is a string\n",
        "        # Lowercase the text\n",
        "        text = text.lower()\n",
        "        # Remove special characters and digits\n",
        "        text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "        # Tokenize text and remove stopwords\n",
        "        stop_words = set(stopwords.words('english'))\n",
        "        words = word_tokenize(text)\n",
        "        words = [word for word in words if word not in stop_words]\n",
        "        return ' '.join(words)\n",
        "    else:\n",
        "        return ''  # Return empty string if it's not a valid string\n",
        "\n",
        "# Apply text cleaning to the reviews\n",
        "df['cleaned_review'] = df['review'].apply(clean_text)\n",
        "\n",
        "# 3. Split the data into features (X) and target (y)\n",
        "X = df['cleaned_review']  # Reviews (features)\n",
        "y = df['sentiment'].apply(lambda x: 1 if x == 'positive' else 0)  # Sentiment (target: 1 for positive, 0 for negative)\n",
        "\n",
        "# Split the dataset into training and testing sets (80% training, 20% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 4. Feature Extraction using TF-IDF\n",
        "vectorizer = TfidfVectorizer(max_features=5000)  # You can adjust max_features as needed\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)\n",
        "\n",
        "# 5. Handle class imbalance using SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "X_res, y_res = smote.fit_resample(X_train_tfidf, y_train)\n",
        "\n",
        "# 6. Train the model (using Naive Bayes as an example)\n",
        "model = MultinomialNB()\n",
        "\n",
        "# Hyperparameter tuning using GridSearchCV\n",
        "param_grid = {'alpha': [0.1, 0.5, 1.0, 2.0, 5.0]}  # Try different values of alpha\n",
        "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy')\n",
        "grid_search.fit(X_res, y_res)\n",
        "\n",
        "# Get the best model from grid search\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# 7. Make predictions\n",
        "y_pred = best_model.predict(X_test_tfidf)\n",
        "\n",
        "# 8. Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Evaluate model using ROC-AUC and Precision-Recall AUC\n",
        "y_probs = best_model.predict_proba(X_test_tfidf)[:, 1]  # Get the probabilities for the positive class\n",
        "roc_auc = roc_auc_score(y_test, y_probs)\n",
        "precision_vals, recall_vals, _ = precision_recall_curve(y_test, y_probs)\n",
        "pr_auc = auc(recall_vals, precision_vals)\n",
        "\n",
        "# Output the evaluation metrics\n",
        "print(f'Accuracy: {accuracy}')\n",
        "print(f'Precision: {precision}')\n",
        "print(f'Recall: {recall}')\n",
        "print(f'F1 Score: {f1}')\n",
        "print(f'ROC-AUC: {roc_auc}')\n",
        "print(f'Precision-Recall AUC: {pr_auc}')\n",
        "print('Confusion Matrix:')\n",
        "print(conf_matrix)\n",
        "\n",
        "# Example of model performance on a single review\n",
        "sample_review = \"This movie was absolutely fantastic!\"\n",
        "sample_review_cleaned = clean_text(sample_review)\n",
        "sample_review_tfidf = vectorizer.transform([sample_review_cleaned])\n",
        "prediction = best_model.predict(sample_review_tfidf)\n",
        "print(f'Sample review sentiment: {\"positive\" if prediction == 1 else \"negative\"}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNCvI4dLDmvs",
        "outputId": "a626da8d-9e20-4e5c-bfb0-b6b32948d152"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9970122497759187\n",
            "Precision: 0.42857142857142855\n",
            "Recall: 0.3333333333333333\n",
            "F1 Score: 0.375\n",
            "ROC-AUC: 0.44793955129485385\n",
            "Precision-Recall AUC: 0.1635375911610308\n",
            "Confusion Matrix:\n",
            "[[3334    4]\n",
            " [   6    3]]\n",
            "Sample review sentiment: positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model and vectorizer for later use (optional)\n",
        "import joblib\n",
        "joblib.dump(best_model, 'sentiment_model.pkl')\n",
        "joblib.dump(vectorizer, 'tfidf_vectorizer.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWqcMI_ND8oC",
        "outputId": "ce716b77-3998-4069-eb26-8012c681aea1"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tfidf_vectorizer.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "284aKVdbEqbJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}